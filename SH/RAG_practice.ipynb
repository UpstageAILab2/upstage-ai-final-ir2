{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(실습-10) RAG 실습\n",
    "실습 개요\n",
    "1) 실습 목적\n",
    "이번 실습에서는 ColBERT와 LLM을 이용하여 RAG를 구현해 본다.\n",
    "RAG 구현을 위해 LLM 프롬프트를 어떻게 사용할 수 있는지 확인한다.\n",
    "2) 수강 목표\n",
    "\n",
    "RAG 구현을 위한 내부 모듈 및 시스템 파이프라인을 이해한다.\n",
    "ColBERT와 OpenAI API를 사용하여 RAG를 실제로 구현할 수 있다.\n",
    "Function calling을 포함한 프롬프트 엔지니어링 방법에 대해 이해한다.\n",
    "실습 목차\n",
    "RAG 개념 이해\n",
    "검색엔진 준비 - ColBERT\n",
    "대화형 IR\n",
    "데이터셋 개요\n",
    "데이터셋: LoTTE 벤치마크의 dev 세트\n",
    "데이터셋 개요\n",
    "LoTTE: ColBERT에서 소개하는 공개 데이터 셋이다.\n",
    "데이터셋 라이센스\n",
    "LoTTE: MIT\n",
    "LoTTE 데이터셋 상세 설명\n",
    "LoTTE 데이터 세트는 Wikipedia와 같은 엔티티 중심의 지식 기반에서는 잘 다루지 않을 수 있는 롱테일 주제에 대한 IR 시스템을 평가하기 위해 설계되었습니다. 이번 실습에서는 주로 반려 동물을 다루고 있는 문서를 사용합니다.\n",
    "환경 설정\n",
    "OpenAI 패키지를 설치한다.\n",
    "RAG용 검색엔진으로 사용할 ColBERT 패키지를 설치한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.6.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.0.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colbert-ir[faiss-gpu,torch] in /opt/conda/lib/python3.10/site-packages (0.2.14)\n",
      "Requirement already satisfied: bitarray in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (2.9.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (2.20.0)\n",
      "Requirement already satisfied: flask in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (3.0.3)\n",
      "Requirement already satisfied: git-python in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (1.0.3)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (1.0.1)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (1.11.1.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (1.12.0)\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (3.7.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (4.66.4)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (4.37.2)\n",
      "Requirement already satisfied: ujson in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (5.10.0)\n",
      "Requirement already satisfied: faiss-gpu>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (1.7.2)\n",
      "Requirement already satisfied: torch==1.13.1 in /opt/conda/lib/python3.10/site-packages (from colbert-ir[faiss-gpu,torch]) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.13.1->colbert-ir[faiss-gpu,torch]) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch==1.13.1->colbert-ir[faiss-gpu,torch]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch==1.13.1->colbert-ir[faiss-gpu,torch]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch==1.13.1->colbert-ir[faiss-gpu,torch]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch==1.13.1->colbert-ir[faiss-gpu,torch]) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->colbert-ir[faiss-gpu,torch]) (68.0.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->colbert-ir[faiss-gpu,torch]) (0.41.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (1.26.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (0.23.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ir[faiss-gpu,torch]) (6.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from flask->colbert-ir[faiss-gpu,torch]) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from flask->colbert-ir[faiss-gpu,torch]) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from flask->colbert-ir[faiss-gpu,torch]) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from flask->colbert-ir[faiss-gpu,torch]) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from flask->colbert-ir[faiss-gpu,torch]) (1.8.2)\n",
      "Requirement already satisfied: gitpython in /opt/conda/lib/python3.10/site-packages (from git-python->colbert-ir[faiss-gpu,torch]) (3.1.43)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (0.12.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (2.6.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy->colbert-ir[faiss-gpu,torch]) (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->colbert-ir[faiss-gpu,torch]) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->colbert-ir[faiss-gpu,torch]) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->colbert-ir[faiss-gpu,torch]) (0.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->colbert-ir[faiss-gpu,torch]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->colbert-ir[faiss-gpu,torch]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->colbert-ir[faiss-gpu,torch]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->colbert-ir[faiss-gpu,torch]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->colbert-ir[faiss-gpu,torch]) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->colbert-ir[faiss-gpu,torch]) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask->colbert-ir[faiss-gpu,torch]) (2.1.1)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy->colbert-ir[faiss-gpu,torch]) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->colbert-ir[faiss-gpu,torch]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->colbert-ir[faiss-gpu,torch]) (2.16.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->colbert-ir[faiss-gpu,torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->colbert-ir[faiss-gpu,torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->colbert-ir[faiss-gpu,torch]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->colbert-ir[faiss-gpu,torch]) (2024.6.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy->colbert-ir[faiss-gpu,torch]) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy->colbert-ir[faiss-gpu,torch]) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy->colbert-ir[faiss-gpu,torch]) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy->colbert-ir[faiss-gpu,torch]) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy->colbert-ir[faiss-gpu,torch]) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy->colbert-ir[faiss-gpu,torch]) (7.0.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython->git-python->colbert-ir[faiss-gpu,torch]) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->colbert-ir[faiss-gpu,torch]) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->colbert-ir[faiss-gpu,torch]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->colbert-ir[faiss-gpu,torch]) (2024.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ir[faiss-gpu,torch]) (5.0.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->colbert-ir[faiss-gpu,torch]) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->colbert-ir[faiss-gpu,torch]) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->colbert-ir[faiss-gpu,torch]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->colbert-ir[faiss-gpu,torch]) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->colbert-ir[faiss-gpu,torch]) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->colbert-ir[faiss-gpu,torch]) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install \"colbert-ir[faiss-gpu, torch]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 417 queries and 268,893 passages\n",
      "how much should i feed my 1 year old english mastiff?\n",
      "In my experience rabbits are very easy to housebreak. They like to pee and poop in the same place every time, so in most cases all you have to do is put a little bit of their waste in the litter box and they will happily use the litter box. It is very important that if they go somewhere else, miss the edge or kick waste out of the box that you clean it up well and immediately as otherwise those spots will become existing places to pee and poop. When you clean the box, save a little bit of waste and put it in the cleaned box so it smells right to them. For a more foolproof method, you can get a piece of wood soaked with their urine and put that in the box along with droppings or cage them so that they are only in their litter box for a week. Generally, if I try the first method and find that they are not using only the box on the first day, I go for the litter box only for a week method. The wood block works well if you are moving from a hutch outdoors to a litter box indoors. If you have an indoor cage, you can use the cage itself as the litter box (or attach a litter box to the section of the cage the rabbit has used for waste.) Be sure to use clay or newsprint litter as the other types arent necessarily good for rabbits. Wood litter is okay if you are sure it isnt fir. The most important thing is to clean anywhere they have an accident. High sided boxes help with avoiding kicking soiled litter out of the box, which is the biggest cause of failure in my experience.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = 'lifestyle'\n",
    "datasplit = 'dev'\n",
    "\n",
    "collection_dataset = load_dataset(\"colbertv2/lotte_passages\", dataset)\n",
    "collection = [x['text'] for x in collection_dataset[datasplit + '_collection']]\n",
    "\n",
    "queries_dataset = load_dataset(\"colbertv2/lotte\", dataset)\n",
    "queries = [x['query'] for x in queries_dataset['search_' + datasplit]]\n",
    "\n",
    "print(f'Loaded {len(queries)} queries and {len(collection):,} passages')\n",
    "print(queries[0])\n",
    "print(collection[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RAG 개념 이해\n",
    "\n",
    "레퍼런스 정보가 있다고 가정하고 극 정보를 토대로 질문에 답하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 라이브러리 및 필요한 모듈을 가져옵니다.\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_KEY = os.getenv('OPENAI_KEY')\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo-1106\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {'role' : \"user\", \"content\": \"너는 누구니\"},\n",
    "    {\"role\" : \"assistant\", \"content\": \"저는 시강 검색 도우미 Good Place 라고 합니다.\"},\n",
    "    {\"role\" : \"user\" ,\"content\": \"강남역 근처 태국 음식 추천해줘\"}\n",
    "]\n",
    "\n",
    "reference =[\n",
    "    {\"식당명\": \"파파야리프\", \"대표 메뉴\": \"똠양꿍\", \"분위기\": \"이국적/이색적\", \"기타\": \"데이트에 적합\"},\n",
    "    {\"식당명\": \"할랄가이즈\", \"대표 메뉴\": \"할랄\", \"분위기\": \"무슬림, 이국적\", \"기타\":\"가성비\"},\n",
    "    {\"식당명\": \"인더비엣\", \"대표 메뉴\": \"팟타야, 쌀국수\", \"분위기\": \"깔끔\", \"기타\": \"해장\"}\n",
    "    \n",
    "]\n",
    "\n",
    "persona = \"\"\"\n",
    "\n",
    "## Name : Good Place\n",
    "\n",
    "## Role : 식당 검색 도우미\n",
    "\n",
    "## Instruction\n",
    "\n",
    "- 사용자의 이전 메시지 정보 및 주어진 검색 결과 (JSON 형태로 제공) 정보를 활용하여 간결하게 답변을 생성한다.\n",
    "- 주어진 검색 결과 정보로 대답할 수 없는 경우는 정보가 부족해서 답을 할 수 없다고 대답한다.\n",
    "- 사용자가 상요한 언어로 답변을 생성한다.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='강남역 근처에서 태국 음식을 즐길 수 있는 몇 가지 좋은 식당이 있습니다. 그 중 하나는 \"타이쇼\"입니다. 이 식당은 정통 태국 음식을 맛볼 수 있는 곳으로 유명합니다. 또한 \"쏘파야\"도 태국 음식을 맛볼 수 있는 좋은 선택지입니다. 이곳에서는 맛있는 태국 요리를 즐길 수 있습니다. 이 외에도 강남역 근처에는 다양한 태국 음식을 즐길 수 있는 식당들이 많이 있으니 찾아보시면 좋을 것 같습니다.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# 레퍼런스 없이 답변 생성하는 경우 - hallucinaion 발생\n",
    "\n",
    "# 그러니까 학습을 진행하지 않고 그냥 자체 gpt로 응답을 할 때 타이쇼라는 음식점은 존재하지만 쏘파 라는 은식점은 존재하지 않는다.\n",
    "\n",
    "result = client.chat.completions.create(\n",
    "    model=llm_model,\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "print(result.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='강남역 근처 태국 음식 추천해드릴게요. \\n\\n1. **파파야리프**\\n   - 대표 메뉴: 똠양꿍\\n   - 분위기: 이국적/이색적\\n   - 기타: 데이트에 적합\\n\\n2. **할랄가이즈**\\n   - 대표 메뉴: 할랄\\n   - 분위기: 무슬림, 이국적\\n   - 기타: 가성비\\n\\n3. **인더비엣**\\n   - 대표 메뉴: 팟타야, 쌀국수\\n   - 분위기: 깔끔\\n   - 기타: 해장\\n\\n어떤 식당을 방문해보고 싶으신가요?', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "content = {\n",
    "    '이전 메시지 정보': messages,\n",
    "    '검색결과': reference\n",
    "}\n",
    "\n",
    "msg = [{\"role\": \"system\", \"content\": persona}, {\"role\": \"assistant\",  \"content\": json.dumps(content, ensure_ascii=False, indent=4)}]\n",
    "\n",
    "result = client.chat.completions.create(\n",
    "    model=llm_model,\n",
    "    messages=msg,\n",
    "    temperature=0,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "print(result.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 검색엔진 준비 - ColBERT\n",
    "\n",
    "빠른 실습을 위해 처음 10,000개의 구절에 대해서만 색인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\n",
    "\n",
    "from colbert import Indexer, Searcher\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries, Collection\n",
    "import numpy\n",
    "import colbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Jun 20, 01:45:22] #> Note: Output directory /root/upstage-ai-final-ir2/SH/experiments/notebook/indexes/test already exists\n",
      "\n",
      "\n",
      "[Jun 20, 01:45:22] #> Will delete 1 files already at /root/upstage-ai-final-ir2/SH/experiments/notebook/indexes/test in 20 seconds...\n",
      "#> Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/__init__.py\", line 1, in <module>\n",
      "    from .trainer import Trainer\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/trainer.py\", line 5, in <module>\n",
      "    from colbert.training.training import train\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/training/training.py\", line 9, in <module>\n",
      "    from colbert.training.rerank_batcher import RerankBatcher\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/training/rerank_batcher.py\", line 9, in <module>\n",
      "    from colbert.data.collection import Collection\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/data/__init__.py\", line 1, in <module>\n",
      "    from .collection import *\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/data/collection.py\", line 10, in <module>\n",
      "    from colbert.evaluation.loaders import load_collection\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/evaluation/loaders.py\", line 8, in <module>\n",
      "    from colbert.parameters import DEVICE\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/parameters.py\", line 3, in <module>\n",
      "    DEVICE = torch.device(\"cuda\")\n",
      "/opt/conda/lib/python3.10/site-packages/colbert/parameters.py:3: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:77.)\n",
      "  DEVICE = torch.device(\"cuda\")\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/__init__.py\", line 2, in <module>\n",
      "    from .indexer import Indexer\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/indexer.py\", line 12, in <module>\n",
      "    from colbert.indexing.collection_indexer import encode\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 8, in <module>\n",
      "    import faiss\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/faiss/__init__.py\", line 18, in <module>\n",
      "    from .loader import *\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/faiss/loader.py\", line 65, in <module>\n",
      "    from .swigfaiss import *\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/faiss/swigfaiss.py\", line 13, in <module>\n",
      "    from . import _swigfaiss\n",
      "AttributeError: _ARRAY_API not found\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: faiss must be imported for indexing\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 3e-6,\n",
      "    \"maxsteps\": 500000,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": null,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"colbert-ir\\/colbertv2.0\",\n",
      "    \"triples\": null,\n",
      "    \"collection\": [\n",
      "        \"list with 10000 elements starting with...\",\n",
      "        [\n",
      "            \"In my experience rabbits are very easy to housebreak. They like to pee and poop in the same place every time, so in most cases all you have to do is put a little bit of their waste in the litter box and they will happily use the litter box. It is very important that if they go somewhere else, miss the edge or kick waste out of the box that you clean it up well and immediately as otherwise those spots will become existing places to pee and poop. When you clean the box, save a little bit of waste and put it in the cleaned box so it smells right to them. For a more foolproof method, you can get a piece of wood soaked with their urine and put that in the box along with droppings or cage them so that they are only in their litter box for a week. Generally, if I try the first method and find that they are not using only the box on the first day, I go for the litter box only for a week method. The wood block works well if you are moving from a hutch outdoors to a litter box indoors. If you have an indoor cage, you can use the cage itself as the litter box (or attach a litter box to the section of the cage the rabbit has used for waste.) Be sure to use clay or newsprint litter as the other types arent necessarily good for rabbits. Wood litter is okay if you are sure it isnt fir. The most important thing is to clean anywhere they have an accident. High sided boxes help with avoiding kicking soiled litter out of the box, which is the biggest cause of failure in my experience.\",\n",
      "            \"...rabbits can be easily trained to use a litter tray, sometimes with more reliability than your average cat! The natural instinct of a wild rabbit to use one area as its latrine is still apparent in its domestic counterparts. (1) The actual process is very similar to pad training a dog or litter box training a cat. Keep the rabbit confined to a small area while training, move any accidents to the litter box, and the rabbit will naturally start using that area for its business. The source link has the details. (1) Litter Training Your Rabbit Emma Magnus MSc Association of Pet Behaviour Counsellors apbc.org.uk\",\n",
      "            \"It could be a multitude of things. Lack of exercise plays a big role in how your dog acts. If they have a lot of unused energy, theyre more likely to act up. Giving him treats or praise will encourage the behavior youre trying to prevent. You want to refrain from treats or praise until hes doing what you want him to do. In the mean time, make it clear to him what you want. You want to be the focus of his attention when you come across a child or another dog. You can do this by keeping him right next to you (never in front of you) by using a short leash. If he tries to pull, tilt the leash upwards. Doing so creates unusual pressure on the bottom of his neck, causing him to look up and see whats going on. If he still wont turn his attention to you, you can forcefully nudge him with the side of your leg until he yields. Ive found with my dog sometimes I have to step in front of her and hold her muzzle, forcing her to look at me. Its also important that you remain calm. Its easy to get upset and dogs have the ability of reading our emotions. If youre tense and angry, hell start tune you out. Source: personal experience with my black lab guided by insight from Cesar Millan\"\n",
      "        ]\n",
      "    ],\n",
      "    \"queries\": null,\n",
      "    \"index_name\": \"test\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/root\\/upstage-ai-final-ir2\\/SH\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-06\\/20\\/01.37.52\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jun 20, 01:45:46] [0] \t\t # of sampled PIDs = 10000 \t sampled_pids[:3] = [6825, 166, 4892]\n",
      "[Jun 20, 01:45:46] [0] \t\t #> Encoding 10000 passages..\n",
      "[Jun 20, 01:46:05] [0] \t\t avg_doclen_est = 180.2436981201172 \t len(local_sample) = 10,000\n",
      "[Jun 20, 01:46:05] [0] \t\t Creaing 16,384 partitions.\n",
      "[Jun 20, 01:46:05] [0] \t\t *Estimated* 1,802,436 embeddings.\n",
      "[Jun 20, 01:46:05] [0] \t\t #> Saving the indexing plan to /root/upstage-ai-final-ir2/SH/experiments/notebook/indexes/test/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 115, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 33, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 67, in run\n",
      "    self.train(shared_lists) # Trains centroids from selected passages\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 220, in train\n",
      "    centroids = self._train_kmeans(sample, shared_lists)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 291, in _train_kmeans\n",
      "    centroids = compute_faiss_kmeans(*args_)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 479, in compute_faiss_kmeans\n",
      "    kmeans = faiss.Kmeans(dim, num_partitions, niter=kmeans_niters, gpu=use_gpu, verbose=True, seed=123)\n",
      "NameError: name 'faiss' is not defined\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m config \u001b[38;5;241m=\u001b[39m ColBERTConfig(doc_maxlen\u001b[38;5;241m=\u001b[39mdoc_maxlen, nbits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, kmeans_niters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;66;03m# kmeans_niters specifies the number of iterations of k-means clustering; 4 is a good and fast default.                                                                           # Consider larger numbers for small datasets.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m indexer \u001b[38;5;241m=\u001b[39m Indexer(checkpoint\u001b[38;5;241m=\u001b[39mcheckpoint, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/colbert/indexer.py:74\u001b[0m, in \u001b[0;36mIndexer.index\u001b[0;34m(self, name, collection, overwrite)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merase()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_does_not_exist \u001b[38;5;129;01mor\u001b[39;00m overwrite \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/colbert/indexer.py:85\u001b[0m, in \u001b[0;36mIndexer.__launch\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Encodes collection into index using the CollectionIndexer class\u001b[39;00m\n\u001b[1;32m     84\u001b[0m launcher \u001b[38;5;241m=\u001b[39m Launcher(encode)\n\u001b[0;32m---> 85\u001b[0m \u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_queues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/colbert/infra/launcher.py:76\u001b[0m, in \u001b[0;36mLauncher.launch\u001b[0;34m(self, custom_config, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m print_memory_stats(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# TODO: If the processes crash upon join, raise an exception and don't block on .get() below!\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([return_value_queue\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m all_procs])\n\u001b[1;32m     77\u001b[0m return_values \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m rank, val \u001b[38;5;129;01min\u001b[39;00m return_values]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_all:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/colbert/infra/launcher.py:76\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m print_memory_stats(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# TODO: If the processes crash upon join, raise an exception and don't block on .get() below!\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([\u001b[43mreturn_value_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m all_procs])\n\u001b[1;32m     77\u001b[0m return_values \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m rank, val \u001b[38;5;129;01min\u001b[39;00m return_values]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_all:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 테스트를 위해 전체 문서 중 10000개만 색인 (약 5분 정도 소요됨)\n",
    "\n",
    "\n",
    "checkpoint = 'colbert-ir/colbertv2.0'\n",
    "index_name = \"test\"\n",
    "doc_maxlen = 300\n",
    "max_id = 10000\n",
    "\n",
    "with Run().context(RunConfig(nranks=1, experiment='notebook')):  # nranks specifies the number of GPUs to use\n",
    "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=2, kmeans_niters=4) # kmeans_niters specifies the number of iterations of k-means clustering; 4 is a good and fast default.                                                                           # Consider larger numbers for small datasets.\n",
    "\n",
    "    indexer = Indexer(checkpoint=checkpoint, config=config)\n",
    "    indexer.index(name=index_name, collection=collection[:max_id], overwrite=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
